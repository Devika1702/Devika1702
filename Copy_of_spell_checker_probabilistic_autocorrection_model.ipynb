{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Devika1702/Devika1702/blob/main/Copy_of_spell_checker_probabilistic_autocorrection_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGoz6YyAnRdr"
      },
      "source": [
        "import re\n",
        "import string\n",
        "from collections import Counter\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGBxOcg6ne-k"
      },
      "source": [
        "def read_corpus(filename):\n",
        "  with open(filename, \"r\") as file:\n",
        "    lines = file.readlines()\n",
        "    words = []\n",
        "    for line in lines:\n",
        "      words += re.findall(r'\\w+', line.lower())\n",
        "\n",
        "  return words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tjtkL_yoMFH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "341fe0b3-e951-457c-f64d-ff67be461607"
      },
      "source": [
        "words = read_corpus(\"./big.txt\")\n",
        "print(f\"There are {len(words)} total words in the corpus\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-b861461bf68e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./big.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"There are {len(words)} total words in the corpus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-11fcc5f7e281>\u001b[0m in \u001b[0;36mread_corpus\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './big.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDKIr2xRoYR6"
      },
      "source": [
        "vocabs = set(words)\n",
        "print(f\"There are {len(vocabs)} unique words in the vocabulary\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-IesLNUoZpc"
      },
      "source": [
        "word_counts = Counter(words)\n",
        "print(word_counts[\"love\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zqFfdkXo61p"
      },
      "source": [
        "total_word_count = float(sum(word_counts.values()))\n",
        "word_probas = {word: word_counts[word] / total_word_count for word in word_counts.keys()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAXiYE7KpkSZ"
      },
      "source": [
        "print(word_probas[\"love\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bygjIHbCpphy"
      },
      "source": [
        "def split(word):\n",
        "  return [(word[:i], word[i:]) for i in range(len(word) + 1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mscT-O_1qAcX"
      },
      "source": [
        "print(split(\"trash\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGrqsaX4qEZf"
      },
      "source": [
        "def delete(word):\n",
        "  return [l + r[1:] for l,r in split(word) if r]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfkxBrydrG_V"
      },
      "source": [
        "print(delete(\"trash\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7IRxUCUrJiL"
      },
      "source": [
        "def swap(word):\n",
        "  return [l + r[1] + r[0] + r[2:] for l, r in split(word) if len(r)>1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "242OacCyrmJR"
      },
      "source": [
        "print(swap(\"trash\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7EX_2rhsHT6"
      },
      "source": [
        "string.ascii_lowercase"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gxA9BRBrolC"
      },
      "source": [
        "def replace(word):\n",
        "  letters = string.ascii_lowercase\n",
        "  return [l + c + r[1:] for l, r in split(word) if r for c in letters]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPaBwRB6sQ-N"
      },
      "source": [
        "print(replace(\"trash\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZKvLwE6sTJu"
      },
      "source": [
        "def insert(word):\n",
        "  letters = string.ascii_lowercase\n",
        "  return [l + c + r for l, r in split(word) for c in letters]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYc17q1csxuB"
      },
      "source": [
        "print(insert(\"trash\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ij3DrMouszUU"
      },
      "source": [
        "def edit1(word):\n",
        "  return set(delete(word) + swap(word) + replace(word) + insert(word))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bsb84qtJtgnX"
      },
      "source": [
        "print(edit1(\"trash\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UebE0pNJtkBI"
      },
      "source": [
        "def edit2(word):\n",
        "  return set(e2 for e1 in edit1(word) for e2 in edit1(e1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4kmHyg8uKoW"
      },
      "source": [
        "print(edit2(\"trash\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edjN5WhquNF0"
      },
      "source": [
        "def correct_spelling(word, vocabulary, word_probabilities):\n",
        "  if word in vocabulary:\n",
        "    print(f\"{word} is already correctly spelt\")\n",
        "    return \n",
        "\n",
        "  suggestions = edit1(word) or edit2(word) or [word]\n",
        "  best_guesses = [w for w in suggestions if w in vocabulary]\n",
        "  return [(w, word_probabilities[w]) for w in best_guesses]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00RcIO-MvuPd"
      },
      "source": [
        "word = \"famile\"\n",
        "corrections = correct_spelling(word, vocabs, word_probas)\n",
        "\n",
        "if corrections:\n",
        "  print(corrections)\n",
        "  probs = np.array([c[1] for c in corrections])\n",
        "  best_ix = np.argmax(probs)\n",
        "  correct = corrections[best_ix][0]\n",
        "  print(f\"{correct} is suggested for {word}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVlZSLFEw5_p"
      },
      "source": [
        "class SpellChecker(object):\n",
        "\n",
        "  def __init__(self, corpus_file_path):\n",
        "    with open(corpus_file_path, \"r\") as file:\n",
        "      lines = file.readlines()\n",
        "      words = []\n",
        "      for line in lines:\n",
        "        words += re.findall(r'\\w+', line.lower())\n",
        "\n",
        "    self.vocabs = set(words)\n",
        "    self.word_counts = Counter(words)\n",
        "    total_words = float(sum(self.word_counts.values()))\n",
        "    self.word_probas = {word: self.word_counts[word] / total_words for word in self.vocabs}\n",
        "\n",
        "  def _level_one_edits(self, word):\n",
        "    letters = string.ascii_lowercase\n",
        "    splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
        "    deletes = [l + r[1:] for l,r in splits if r]\n",
        "    swaps = [l + r[1] + r[0] + r[2:] for l, r in splits if len(r)>1]\n",
        "    replaces = [l + c + r[1:] for l, r in splits if r for c in letters]\n",
        "    inserts = [l + c + r for l, r in splits for c in letters] \n",
        "\n",
        "    return set(deletes + swaps + replaces + inserts)\n",
        "\n",
        "  def _level_two_edits(self, word):\n",
        "    return set(e2 for e1 in self._level_one_edits(word) for e2 in self._level_one_edits(e1))\n",
        "\n",
        "  def check(self, word):\n",
        "    candidates = self._level_one_edits(word) or self._level_two_edits(word) or [word]\n",
        "    valid_candidates = [w for w in candidates if w in self.vocabs]\n",
        "    return sorted([(c, self.word_probas[c]) for c in valid_candidates], key=lambda tup: tup[1], reverse=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6rNozhK-vP-"
      },
      "source": [
        "checker = SpellChecker(\"./big.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4ITtlnP-zEC"
      },
      "source": [
        "checker.check(\"sentense\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFl1vRi7_alJ"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}